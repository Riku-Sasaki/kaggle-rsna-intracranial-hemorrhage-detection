{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "\n",
    "def disp_full(x, drows=False, dcols=True):\n",
    "    if drows:\n",
    "        pd.set_option('display.max_rows', x.shape[0])\n",
    "    if dcols:\n",
    "        pd.set_option('display.max_columns', x.shape[1])\n",
    "    display(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feats(df):\n",
    "    df['ImagePositionPatient_2'] = df['ImagePositionPatient'].progress_apply(lambda x: x[2])\n",
    "    df = df.merge(df.groupby(\n",
    "        ['StudyInstanceUID']\n",
    "    )['ImagePositionPatient_2'].agg(position_min='min', position_max='max').reset_index(), on='StudyInstanceUID')\n",
    "    df['position'] = (df['ImagePositionPatient_2'] - df['position_min']) / (df['position_max'] - df['position_min'])\n",
    "    res = df.sort_values(by=['StudyInstanceUID', 'position'])\n",
    "    return res\n",
    "\n",
    "\n",
    "def pred_agg1(df):\n",
    "    new_feats = []\n",
    "    \n",
    "    for c in target_cols:\n",
    "        tmp = df.groupby(\n",
    "            ['StudyInstanceUID']\n",
    "        )[c+'_pred'].agg(['min', 'max', 'mean', 'std']).reset_index()\n",
    "        tmp.columns = ['StudyInstanceUID', c+'_min', c+'_max', c+'_mean', c+'_std']\n",
    "        if c != 'any':\n",
    "            del tmp['StudyInstanceUID']\n",
    "        new_feats.append(tmp)\n",
    "    new_feats = pd.concat(new_feats, axis=1)\n",
    "    df = pd.merge(df, new_feats, on='StudyInstanceUID', how='left')\n",
    "    for c in target_cols:\n",
    "        df[c+'_diff'] = df[c+'_pred'] - df[c+'_mean']\n",
    "        df[c+'_div'] = df[c+'_pred'] / df[c+'_mean']\n",
    "        df[c+'_scaled'] = (df[c+'_pred'] - df[c+'_mean']) / df[c+'_std']\n",
    "    return df\n",
    "\n",
    "\n",
    "def pred_agg2(df):\n",
    "    a1 = df.groupby('StudyInstanceUID')[[col for col in df.columns if col.endswith('_pred')]].rolling(3, min_periods=1, center=True).mean().values\n",
    "    a2 = df.groupby('StudyInstanceUID')[[col for col in df.columns if col.endswith('_pred')]].rolling(5, min_periods=1, center=True).mean().values\n",
    "    a3 = df.groupby('StudyInstanceUID')[[col for col in df.columns if col.endswith('_pred')]].rolling(1, min_periods=1, center=True).mean().values\n",
    "    new_feats1 = pd.DataFrame(a1, columns = [c+'_3roll' for c in target_cols])\n",
    "    new_feats2 = pd.DataFrame(a2, columns = [c+'_5roll' for c in target_cols])\n",
    "    new_feats3 = pd.DataFrame(a1 - a3, columns = [c+'_3rolldiff' for c in target_cols])\n",
    "    new_feats4 = pd.DataFrame(a2 - a3, columns = [c+'_5rolldiff' for c in target_cols])\n",
    "    new_feats5 = pd.DataFrame(a1 / a3, columns = [c+'_3rolldiv' for c in target_cols])\n",
    "    new_feats6 = pd.DataFrame(a2 / a3, columns = [c+'_5rolldiv' for c in target_cols])\n",
    "    new_feats1.index = df.index\n",
    "    new_feats2.index = df.index\n",
    "    new_feats3.index = df.index\n",
    "    new_feats4.index = df.index\n",
    "    new_feats5.index = df.index\n",
    "    new_feats6.index = df.index\n",
    "    df = pd.concat([df, new_feats1, new_feats2, new_feats3, new_feats4, new_feats5, new_feats6], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "df_all = []\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "n_tta = 5\n",
    "for n_fold in range(5):\n",
    "    df = pd.read_pickle(\"data_for_stacking/appian/fold{}_ep2_valid_tta5.pkl\".format(n_fold))\n",
    "    tmp = np.zeros([len(df[0]['ids']), 6])\n",
    "    for i in range(n_tta):\n",
    "        tmp += df[i]['outputs'] / n_tta\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [tar_col + '_pred' for tar_col in target_cols]\n",
    "    tmp['ID'] = df[0]['ids']\n",
    "    tmp['folds'] = n_fold\n",
    "    tmp2 = pd.DataFrame(df[0]['targets'], columns = target_cols)\n",
    "    df_all.append(pd.concat([tmp, tmp2], axis=1))\n",
    "df_all = pd.concat(df_all)\n",
    "tr_meta = pd.read_pickle('data_for_stacking/cache/train_raw.pkl')\n",
    "train = pd.merge(df_all, tr_meta, on='ID', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|██████████| 78363/78363 [00:00<00:00, 413297.11it/s]\n",
      "my bar!: 100%|██████████| 78363/78363 [00:00<00:00, 423155.28it/s]\n",
      "my bar!: 100%|██████████| 78363/78363 [00:00<00:00, 425947.10it/s]\n",
      "my bar!: 100%|██████████| 78363/78363 [00:00<00:00, 418714.94it/s]\n",
      "my bar!: 100%|██████████| 78363/78363 [00:00<00:00, 425111.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "df_all_ts = []\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "n_tta = 5\n",
    "for n_fold in range(5):\n",
    "    df = pd.read_pickle(\"data_for_stacking/appian/fold{}_ep2_test_tta5.pkl\".format(n_fold))\n",
    "    tmp = np.zeros([len(df[0]['ids']), 6])\n",
    "    for i in range(n_tta):\n",
    "        tmp += df[i]['outputs'] / n_tta\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [tar_col + '_pred' for tar_col in target_cols]\n",
    "    tmp['ID'] = df[n_fold]['ids']\n",
    "    tmp['folds'] = n_fold\n",
    "    df_all_ts.append(tmp)\n",
    "\n",
    "ts_meta = pd.read_pickle('data_for_stacking/cache/test_raw.pkl')\n",
    "test_list = []\n",
    "for n_fold in range(5):\n",
    "    test = pd.merge(df_all_ts[n_fold], ts_meta, on='ID', how='inner')\n",
    "    test = make_feats(test)\n",
    "    test = pred_agg1(test)\n",
    "    test = pred_agg2(test)\n",
    "    test_list.append(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageOrientationPatient\n",
      "187\n",
      "ImagePositionPatient\n",
      "696908\n",
      "Modality\n",
      "0\n",
      "PhotometricInterpretation\n",
      "0\n",
      "PixelSpacing\n",
      "221\n",
      "WindowCenter\n",
      "41\n",
      "WindowWidth\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# 学習用col\n",
    "X_cols = train.columns.drop(['StudyInstanceUID', 'ID', 'folds', 'labels', 'n_label', 'SOPInstanceUID', 'PatientID',\n",
    "       'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID'] + target_cols)\n",
    "# lgbにいれるため、object colはlabel encoding\n",
    "for c in X_cols:\n",
    "    if train[c].dtype == 'O':\n",
    "        print(c)\n",
    "        tmp = pd.concat([train[[c]], test_list[0][[c]]]).reset_index(drop=True)\n",
    "        tmp = pd.factorize(tmp[c])[0]\n",
    "        print(tmp.max())\n",
    "        train[c] = tmp[:len(train)]\n",
    "        for n_fold in range(5):\n",
    "            test_list[n_fold][c] = tmp[len(train):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.116963\n",
      "0.11646785944210827\n",
      "0.11696295249092052\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.0165623\n",
      "0.016153468849789597\n",
      "0.016562305350467578\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.0956264\n",
      "0.09523852711521777\n",
      "0.09562638475691988\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.0782203\n",
      "0.07882641153220848\n",
      "0.07822029875417118\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0332188\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.0331812\n",
      "0.032152052259385576\n",
      "0.03318123065510912\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.0473833\n",
      "0.04648049604358661\n",
      "0.047383332197775144\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.107845\n",
      "0.10819263508485565\n",
      "0.10784480543633888\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.0172793\n",
      "0.018442638682996813\n",
      "0.01727927541391466\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.08787\n",
      "0.0882706800586438\n",
      "0.08787000570762286\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.0736434\n",
      "0.07336556074593668\n",
      "0.07364340229642719\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.0307548\n",
      "0.030134404186900214\n",
      "0.030754811877237217\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0533893\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.0533511\n",
      "0.05373267059752665\n",
      "0.05335114138672573\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.112686\n",
      "0.11279097030253843\n",
      "0.11268621756745688\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.0161483\n",
      "0.017203932261702286\n",
      "0.01614830367258503\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.0869664\n",
      "0.08638670519986687\n",
      "0.08696641380839767\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.0722442\n",
      "0.0720613060843844\n",
      "0.07224422052429898\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0299499\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.0299427\n",
      "0.029663330849120022\n",
      "0.029942684724684483\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.0493614\n",
      "0.048669049086262337\n",
      "0.04936140920394266\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.111651\n",
      "0.11154235686298361\n",
      "0.11165132037275735\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.0166896\n",
      "0.017112484075369083\n",
      "0.016689571869163457\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0891204\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.0890935\n",
      "0.08968886733758084\n",
      "0.0890934559218909\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.0787926\n",
      "0.07821472250541038\n",
      "0.07879258799720211\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.0301993\n",
      "0.0292175799315157\n",
      "0.03019933552944493\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.0476405\n",
      "0.04718440562940023\n",
      "0.047640548179906435\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.113505\n",
      "0.11452738405456923\n",
      "0.11350479109806429\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.0152251\n",
      "0.014589386642161545\n",
      "0.015225137165013409\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.0947092\n",
      "0.09444942431337276\n",
      "0.0947091723166704\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.0762945\n",
      "0.07639750032428916\n",
      "0.07629452277827137\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.03037\n",
      "0.029362118628485933\n",
      "0.03036997062369535\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.0497669\n",
      "0.04900867600743965\n",
      "0.049766899299244584\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "stack_preds = []\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 5,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"verbosity\": 0,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "res = []\n",
    "pred_test = []\n",
    "for i in range(5):\n",
    "    tr = train.query('folds != @i')\n",
    "    va = train.query('folds == @i')\n",
    "    preds = pd.DataFrame(np.zeros([len(va), 6]), columns = [c + '_pred' for c in target_cols])\n",
    "    for tar_col in target_cols:\n",
    "        tr_D = lgb.Dataset(tr[X_cols], tr[tar_col])\n",
    "        va_D = lgb.Dataset(va[X_cols], va[tar_col])\n",
    "        clf = lgb.train(params, tr_D, 10000, valid_sets=va_D, verbose_eval=100,\n",
    "                                    early_stopping_rounds=10)\n",
    "        preds[tar_col + '_pred'] = clf.predict(va[X_cols])\n",
    "        pred_test.append(clf.predict(test_list[i][X_cols]))\n",
    "#         preds[tar_col + '_pred'] = clf.predict(va[X_cols])\n",
    "        print(log_loss(va[tar_col], va[tar_col + '_pred']))\n",
    "        print(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        print('-'*80)\n",
    "        res.append(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "    print('='*80)\n",
    "    stack_preds.append(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_pred</th>\n",
       "      <th>epidural_pred</th>\n",
       "      <th>subdural_pred</th>\n",
       "      <th>subarachnoid_pred</th>\n",
       "      <th>intraventricular_pred</th>\n",
       "      <th>intraparenchymal_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.128484</td>\n",
       "      <td>0.110060</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0.971263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133855</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133856</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133857</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133858</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133859</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133860 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        any_pred  epidural_pred  subdural_pred  subarachnoid_pred  \\\n",
       "0       0.000681       0.000385       0.000549           0.000361   \n",
       "1       0.990242       0.003955       0.128484           0.110060   \n",
       "2       0.003136       0.000385       0.002269           0.000504   \n",
       "3       0.002866       0.000385       0.001692           0.000476   \n",
       "4       0.012694       0.000385       0.005301           0.004227   \n",
       "...          ...            ...            ...                ...   \n",
       "133855  0.000746       0.000385       0.000611           0.000293   \n",
       "133856  0.000725       0.000385       0.000554           0.000333   \n",
       "133857  0.004352       0.000385       0.001877           0.001450   \n",
       "133858  0.004718       0.000523       0.004542           0.001625   \n",
       "133859  0.001064       0.000385       0.000821           0.000291   \n",
       "\n",
       "        intraventricular_pred  intraparenchymal_pred  \n",
       "0                    0.000134               0.000350  \n",
       "1                    0.018366               0.971263  \n",
       "2                    0.000151               0.000387  \n",
       "3                    0.000163               0.000494  \n",
       "4                    0.000215               0.001712  \n",
       "...                       ...                    ...  \n",
       "133855               0.000134               0.000380  \n",
       "133856               0.000157               0.000427  \n",
       "133857               0.000174               0.000971  \n",
       "133858               0.000133               0.000388  \n",
       "133859               0.000133               0.000350  \n",
       "\n",
       "[133860 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_pickle(\"data_for_stacking/sasaki_senet154_customlabels/fold0_ep2_valid_tta5.pkl\")\n",
    "old_df = pd.read_pickle(\"data_for_stacking/sasaki_se_resnext_410//fold0_ep2_valid_tta5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "new_df = pd.DataFrame(new_df[0][\"outputs\"], columns=[\"new_\"+target_col for target_col in target_cols])\n",
    "old_df = pd.DataFrame(old_df[0][\"outputs\"], columns=[\"old_\"+target_col for target_col in target_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([old_df, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_any</th>\n",
       "      <th>old_epidural</th>\n",
       "      <th>old_subdural</th>\n",
       "      <th>old_subarachnoid</th>\n",
       "      <th>old_intraventricular</th>\n",
       "      <th>old_intraparenchymal</th>\n",
       "      <th>new_any</th>\n",
       "      <th>new_epidural</th>\n",
       "      <th>new_subdural</th>\n",
       "      <th>new_subarachnoid</th>\n",
       "      <th>new_intraventricular</th>\n",
       "      <th>new_intraparenchymal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>old_any</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>0.688876</td>\n",
       "      <td>0.693457</td>\n",
       "      <td>0.522691</td>\n",
       "      <td>0.632090</td>\n",
       "      <td>0.944920</td>\n",
       "      <td>0.181529</td>\n",
       "      <td>0.651793</td>\n",
       "      <td>0.688468</td>\n",
       "      <td>0.549907</td>\n",
       "      <td>0.660052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>old_epidural</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216977</td>\n",
       "      <td>0.094160</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.086278</td>\n",
       "      <td>0.212037</td>\n",
       "      <td>0.692956</td>\n",
       "      <td>0.233947</td>\n",
       "      <td>0.102997</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.103233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>old_subdural</td>\n",
       "      <td>0.688876</td>\n",
       "      <td>0.216977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366443</td>\n",
       "      <td>0.093449</td>\n",
       "      <td>0.233626</td>\n",
       "      <td>0.650575</td>\n",
       "      <td>0.168895</td>\n",
       "      <td>0.931208</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.110430</td>\n",
       "      <td>0.258264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>old_subarachnoid</td>\n",
       "      <td>0.693457</td>\n",
       "      <td>0.094160</td>\n",
       "      <td>0.366443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>0.421064</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>0.090399</td>\n",
       "      <td>0.345653</td>\n",
       "      <td>0.927378</td>\n",
       "      <td>0.364495</td>\n",
       "      <td>0.453049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>old_intraventricular</td>\n",
       "      <td>0.522691</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.093449</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360995</td>\n",
       "      <td>0.494551</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.321794</td>\n",
       "      <td>0.923466</td>\n",
       "      <td>0.391170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>old_intraparenchymal</td>\n",
       "      <td>0.632090</td>\n",
       "      <td>0.086278</td>\n",
       "      <td>0.233626</td>\n",
       "      <td>0.421064</td>\n",
       "      <td>0.360995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599629</td>\n",
       "      <td>0.082180</td>\n",
       "      <td>0.221528</td>\n",
       "      <td>0.411233</td>\n",
       "      <td>0.387634</td>\n",
       "      <td>0.936717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_any</td>\n",
       "      <td>0.944920</td>\n",
       "      <td>0.212037</td>\n",
       "      <td>0.650575</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>0.494551</td>\n",
       "      <td>0.599629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211156</td>\n",
       "      <td>0.688771</td>\n",
       "      <td>0.723781</td>\n",
       "      <td>0.583304</td>\n",
       "      <td>0.690047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_epidural</td>\n",
       "      <td>0.181529</td>\n",
       "      <td>0.692956</td>\n",
       "      <td>0.168895</td>\n",
       "      <td>0.090399</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.082180</td>\n",
       "      <td>0.211156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202803</td>\n",
       "      <td>0.118782</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.114246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_subdural</td>\n",
       "      <td>0.651793</td>\n",
       "      <td>0.233947</td>\n",
       "      <td>0.931208</td>\n",
       "      <td>0.345653</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.221528</td>\n",
       "      <td>0.688771</td>\n",
       "      <td>0.202803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384175</td>\n",
       "      <td>0.126452</td>\n",
       "      <td>0.273103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_subarachnoid</td>\n",
       "      <td>0.688468</td>\n",
       "      <td>0.102997</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.927378</td>\n",
       "      <td>0.321794</td>\n",
       "      <td>0.411233</td>\n",
       "      <td>0.723781</td>\n",
       "      <td>0.118782</td>\n",
       "      <td>0.384175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417820</td>\n",
       "      <td>0.485162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_intraventricular</td>\n",
       "      <td>0.549907</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.110430</td>\n",
       "      <td>0.364495</td>\n",
       "      <td>0.923466</td>\n",
       "      <td>0.387634</td>\n",
       "      <td>0.583304</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.126452</td>\n",
       "      <td>0.417820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new_intraparenchymal</td>\n",
       "      <td>0.660052</td>\n",
       "      <td>0.103233</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.453049</td>\n",
       "      <td>0.391170</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>0.690047</td>\n",
       "      <td>0.114246</td>\n",
       "      <td>0.273103</td>\n",
       "      <td>0.485162</td>\n",
       "      <td>0.465268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       old_any  old_epidural  old_subdural  old_subarachnoid  \\\n",
       "old_any               1.000000      0.227051      0.688876          0.693457   \n",
       "old_epidural          0.227051      1.000000      0.216977          0.094160   \n",
       "old_subdural          0.688876      0.216977      1.000000          0.366443   \n",
       "old_subarachnoid      0.693457      0.094160      0.366443          1.000000   \n",
       "old_intraventricular  0.522691      0.010148      0.093449          0.310449   \n",
       "old_intraparenchymal  0.632090      0.086278      0.233626          0.421064   \n",
       "new_any               0.944920      0.212037      0.650575          0.658295   \n",
       "new_epidural          0.181529      0.692956      0.168895          0.090399   \n",
       "new_subdural          0.651793      0.233947      0.931208          0.345653   \n",
       "new_subarachnoid      0.688468      0.102997      0.372899          0.927378   \n",
       "new_intraventricular  0.549907      0.018130      0.110430          0.364495   \n",
       "new_intraparenchymal  0.660052      0.103233      0.258264          0.453049   \n",
       "\n",
       "                      old_intraventricular  old_intraparenchymal   new_any  \\\n",
       "old_any                           0.522691              0.632090  0.944920   \n",
       "old_epidural                      0.010148              0.086278  0.212037   \n",
       "old_subdural                      0.093449              0.233626  0.650575   \n",
       "old_subarachnoid                  0.310449              0.421064  0.658295   \n",
       "old_intraventricular              1.000000              0.360995  0.494551   \n",
       "old_intraparenchymal              0.360995              1.000000  0.599629   \n",
       "new_any                           0.494551              0.599629  1.000000   \n",
       "new_epidural                      0.013900              0.082180  0.211156   \n",
       "new_subdural                      0.093595              0.221528  0.688771   \n",
       "new_subarachnoid                  0.321794              0.411233  0.723781   \n",
       "new_intraventricular              0.923466              0.387634  0.583304   \n",
       "new_intraparenchymal              0.391170              0.936717  0.690047   \n",
       "\n",
       "                      new_epidural  new_subdural  new_subarachnoid  \\\n",
       "old_any                   0.181529      0.651793          0.688468   \n",
       "old_epidural              0.692956      0.233947          0.102997   \n",
       "old_subdural              0.168895      0.931208          0.372899   \n",
       "old_subarachnoid          0.090399      0.345653          0.927378   \n",
       "old_intraventricular      0.013900      0.093595          0.321794   \n",
       "old_intraparenchymal      0.082180      0.221528          0.411233   \n",
       "new_any                   0.211156      0.688771          0.723781   \n",
       "new_epidural              1.000000      0.202803          0.118782   \n",
       "new_subdural              0.202803      1.000000          0.384175   \n",
       "new_subarachnoid          0.118782      0.384175          1.000000   \n",
       "new_intraventricular      0.032992      0.126452          0.417820   \n",
       "new_intraparenchymal      0.114246      0.273103          0.485162   \n",
       "\n",
       "                      new_intraventricular  new_intraparenchymal  \n",
       "old_any                           0.549907              0.660052  \n",
       "old_epidural                      0.018130              0.103233  \n",
       "old_subdural                      0.110430              0.258264  \n",
       "old_subarachnoid                  0.364495              0.453049  \n",
       "old_intraventricular              0.923466              0.391170  \n",
       "old_intraparenchymal              0.387634              0.936717  \n",
       "new_any                           0.583304              0.690047  \n",
       "new_epidural                      0.032992              0.114246  \n",
       "new_subdural                      0.126452              0.273103  \n",
       "new_subarachnoid                  0.417820              0.485162  \n",
       "new_intraventricular              1.000000              0.465268  \n",
       "new_intraparenchymal              0.465268              1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
