{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "def wlogloss(targets, preds):\n",
    "    target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "    res = 0\n",
    "    for col in target_cols:\n",
    "        res += log_loss(targets[col], preds[col+'_pred'])\n",
    "        if col == 'any':\n",
    "            res += log_loss(targets[col], preds[col+'_pred'])\n",
    "    res /= 7\n",
    "    return res\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stack_feats_ts.pickle', 'rb') as f:\n",
    "    test_list = pickle.load(f)\n",
    "with open('stack_feats_tr.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_6model_fasterfeats.pickle', 'rb') as f:\n",
    "    train_ = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train2.drop(['folds', 'StudyInstanceUID'] + target_cols, axis=1), on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = train.columns.drop(['ID', 'folds', 'StudyInstanceUID'] + target_cols)\n",
    "# X_cols = test_list[0].columns.drop(['ID'])\n",
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in target_cols:\n",
    "    del train[c]\n",
    "    train[c] = train_[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "stack_preds = []\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 5,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"verbosity\": 0,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "res = []\n",
    "pred_test = []\n",
    "fi = {}\n",
    "for c in target_cols:\n",
    "    fi[c] = []\n",
    "stack_preds_valid = []\n",
    "for i in range(5):\n",
    "    tr = train.query('folds != @i')\n",
    "    va = train.query('folds == @i')\n",
    "    preds = pd.DataFrame(np.zeros([len(va), 6]), columns = [c + '_pred' for c in target_cols])\n",
    "    for tar_col in target_cols:\n",
    "        tr_D = lgb.Dataset(tr[X_cols], tr[tar_col])\n",
    "        va_D = lgb.Dataset(va[X_cols], va[tar_col])\n",
    "        clf = lgb.train(params, tr_D, 10000, valid_sets=va_D, verbose_eval=100,\n",
    "                                    early_stopping_rounds=120)\n",
    "        preds[tar_col + '_pred'] = clf.predict(va[X_cols])\n",
    "#         pred_test.append(clf.predict(test_list[i][X_cols]))\n",
    "        df_fi = pd.DataFrame(clf.feature_importance(importance_type='gain'), index = X_cols, columns=['FI_score'])\n",
    "        fi[tar_col].append(df_fi)\n",
    "        print(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        res.append(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        print('-'*80)\n",
    "    print('='*80)\n",
    "    stack_preds.append([va['ID'], preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(res):\n",
    "    score = 0\n",
    "    for i, r in enumerate(res):\n",
    "        if i %6 == 0:\n",
    "            score += 2*r\n",
    "        else:\n",
    "            score += r\n",
    "    return score/5/7\n",
    "get_score(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
