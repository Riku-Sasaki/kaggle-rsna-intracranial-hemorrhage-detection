{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "def wlogloss(targets, preds):\n",
    "    target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "    res = 0\n",
    "    for col in target_cols:\n",
    "        res += log_loss(targets[col], preds[col+'_pred'])\n",
    "        if col == 'any':\n",
    "            res += log_loss(targets[col], preds[col+'_pred'])\n",
    "    res /= 7\n",
    "    return res\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stack_feats_ts.pickle', 'rb') as f:\n",
    "    test_list = pickle.load(f)\n",
    "with open('stack_feats_tr.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_6model_fasterfeats.pickle', 'rb') as f:\n",
    "    train_ = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train2.drop(['folds', 'StudyInstanceUID'] + target_cols, axis=1), on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols = train.columns.drop(['ID', 'folds', 'StudyInstanceUID'] + target_cols)\n",
    "# X_cols = test_list[0].columns.drop(['ID'])\n",
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in target_cols:\n",
    "    del train[c]\n",
    "    train[c] = train_[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.103272\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's binary_logloss: 0.103013\n",
      "0.10301337820302264\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0171604\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's binary_logloss: 0.016368\n",
      "0.016367987275621037\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0865999\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's binary_logloss: 0.0860483\n",
      "0.0860483331691216\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0667254\n",
      "[200]\tvalid_0's binary_logloss: 0.0670388\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.0667097\n",
      "0.06670968283493958\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0292906\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.0291271\n",
      "0.029127104201386894\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0383524\n",
      "[200]\tvalid_0's binary_logloss: 0.038423\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.0383121\n",
      "0.03831207386937499\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0949293\n",
      "[200]\tvalid_0's binary_logloss: 0.0950251\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.0948868\n",
      "0.0948867706984196\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0165851\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's binary_logloss: 0.0161445\n",
      "0.016144499870855464\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0783739\n",
      "[200]\tvalid_0's binary_logloss: 0.078901\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.078172\n",
      "0.07817202467565254\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0637905\n",
      "[200]\tvalid_0's binary_logloss: 0.0641824\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.0636874\n",
      "0.06368735503399522\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0253097\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.0252556\n",
      "0.02525561008663662\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0451623\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.0449438\n",
      "0.04494383628538534\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0981482\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's binary_logloss: 0.0979942\n",
      "0.0979942167781421\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0155414\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.0152002\n",
      "0.015200240793376372\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0776053\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.0774006\n",
      "0.07740057687805185\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0636186\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.0635162\n",
      "0.06351620894695494\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0245246\n",
      "[200]\tvalid_0's binary_logloss: 0.0245602\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.0245141\n",
      "0.024514083152068135\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0422862\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's binary_logloss: 0.04204\n",
      "0.04204003319816375\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0992539\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.0990133\n",
      "0.09901327920149036\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0167144\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.0163545\n",
      "0.016354484441734953\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0805822\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.0802194\n",
      "0.08021939938489484\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0703669\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.0701092\n",
      "0.07010921638636894\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0250443\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.0249099\n",
      "0.02490986178497046\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0410922\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.0409578\n",
      "0.04095784764482725\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.101126\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.101073\n",
      "0.10107337220438045\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0152046\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.0148807\n",
      "0.014880650087292772\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0855635\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's binary_logloss: 0.0849569\n",
      "0.0849568502869675\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.0697622\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.0695771\n",
      "0.06957709935678727\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0257017\n",
      "[200]\tvalid_0's binary_logloss: 0.0257671\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.0256783\n",
      "0.025678312884479214\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0424329\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.042313\n",
      "0.04231296335799633\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "CPU times: user 1h 29min 14s, sys: 24.7 s, total: 1h 29min 38s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "stack_preds = []\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 5,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"verbosity\": 0,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "res = []\n",
    "pred_test = []\n",
    "fi = {}\n",
    "for c in target_cols:\n",
    "    fi[c] = []\n",
    "stack_preds_valid = []\n",
    "for i in range(5):\n",
    "    tr = train.query('folds != @i')\n",
    "    va = train.query('folds == @i')\n",
    "    preds = pd.DataFrame(np.zeros([len(va), 6]), columns = [c + '_pred' for c in target_cols])\n",
    "    for tar_col in target_cols:\n",
    "        tr_D = lgb.Dataset(tr[X_cols], tr[tar_col])\n",
    "        va_D = lgb.Dataset(va[X_cols], va[tar_col])\n",
    "        clf = lgb.train(params, tr_D, 10000, valid_sets=va_D, verbose_eval=100,\n",
    "                                    early_stopping_rounds=120)\n",
    "        preds[tar_col + '_pred'] = clf.predict(va[X_cols])\n",
    "#         pred_test.append(clf.predict(test_list[i][X_cols]))\n",
    "        df_fi = pd.DataFrame(clf.feature_importance(importance_type='gain'), index = X_cols, columns=['FI_score'])\n",
    "        fi[tar_col].append(df_fi)\n",
    "        print(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        res.append(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        print('-'*80)\n",
    "    print('='*80)\n",
    "    stack_preds.append([va['ID'], preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06141023914453756"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_score(res):\n",
    "    score = 0\n",
    "    for i, r in enumerate(res):\n",
    "        if i %6 == 0:\n",
    "            score += 2*r\n",
    "        else:\n",
    "            score += r\n",
    "    return score/5/7\n",
    "get_score(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
