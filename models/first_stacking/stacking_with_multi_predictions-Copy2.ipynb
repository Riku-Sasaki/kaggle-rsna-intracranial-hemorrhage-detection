{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "def wlogloss(targets, preds):\n",
    "    target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "    res = 0\n",
    "    for col in target_cols:\n",
    "        res += log_loss(targets[col], preds[col+'_pred'])\n",
    "        if col == 'any':\n",
    "            res += log_loss(targets[col], preds[col+'_pred'])\n",
    "    res /= 7\n",
    "    return res\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_stackfeats_1_2.pickle', 'rb') as f:\n",
    "    test_list1 = pickle.load(f)\n",
    "with open('train_stackfeats_1_2.pickle', 'rb') as f:\n",
    "    train1 = pickle.load(f)\n",
    "with open('test_stackfeats_3_4.pickle', 'rb') as f:\n",
    "    test_list2 = pickle.load(f)\n",
    "with open('train_stackfeats_3_4.pickle', 'rb') as f:\n",
    "    train2 = pickle.load(f)\n",
    "with open('test_stackfeats_5_6.pickle', 'rb') as f:\n",
    "    test_list3 = pickle.load(f)\n",
    "with open('train_stackfeats_5_6.pickle', 'rb') as f:\n",
    "    train3 = pickle.load(f)\n",
    "with open('test_stackfeats_7_8.pickle', 'rb') as f:\n",
    "    test_list4 = pickle.load(f)\n",
    "with open('train_stackfeats_7_8.pickle', 'rb') as f:\n",
    "    train4 = pickle.load(f)\n",
    "with open('test_stackfeats_9_10_11.pickle', 'rb') as f:\n",
    "    test_list5 = pickle.load(f)\n",
    "with open('train_stackfeats_9_10_11.pickle', 'rb') as f:\n",
    "    train5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = test_list1\n",
    "for i in range(5):\n",
    "    tmp = test_list[i]\n",
    "    tmp = tmp.merge(test_list2[i], on='ID', how='left')\n",
    "    tmp = tmp.merge(test_list3[i], on='ID', how='left')\n",
    "    tmp = tmp.merge(test_list4[i], on='ID', how='left')\n",
    "    tmp = tmp.merge(test_list5[i], on='ID', how='left')\n",
    "    test_list[i] = tmp\n",
    "train = train1\n",
    "train = train.merge(train2.drop(target_cols + ['StudyInstanceUID', 'folds'], axis=1), on='ID', how='left')\n",
    "train = train.merge(train3.drop(target_cols + ['StudyInstanceUID', 'folds'], axis=1), on='ID', how='left')\n",
    "train = train.merge(train4.drop(target_cols + ['StudyInstanceUID', 'folds'], axis=1), on='ID', how='left')\n",
    "train = train.merge(train5.drop(target_cols + ['StudyInstanceUID', 'folds'], axis=1), on='ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('test_8models_stackfeats.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_list, f)\n",
    "# with open('train_8model_stackfeats.pickle', 'wb') as f:\n",
    "#     pickle.dump(train, f)\n",
    "# import pickle\n",
    "# with open('test_8models_stackfeats.pickle', 'rb') as f:\n",
    "#     test_list = pickle.load(f)\n",
    "# with open('train_8model_stackfeats.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "import pickle\n",
    "with open('test_10models_stackfeats.pickle', 'wb') as f:\n",
    "    pickle.dump(test_list, f)\n",
    "with open('train_10model_stackfeats.pickle', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "import pickle\n",
    "with open('test_10models_stackfeats.pickle', 'rb') as f:\n",
    "    test_list = pickle.load(f)\n",
    "with open('train_10model_stackfeats.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for n_fold in range(5):\n",
    "    appian_feats = pd.read_pickle(f'../prediction/appian_feats/fold{n_fold}_ep2_valid_tta1_feats.pkl')\n",
    "    df = pd.DataFrame(appian_feats[0]['outputs'], columns=[f'appian_cnn_{i}' for i in range(2048)])\n",
    "    df['ID'] = appian_feats[0]['ids']\n",
    "    df_list.append(df)\n",
    "df_appian_tr = pd.concat(df_list)\n",
    "train = train.merge(df_appian_tr, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_fold in range(5):\n",
    "    appian_feats = pd.read_pickle(f'../prediction/appian_feats/fold{n_fold}_ep2_test_tta1_feats.pkl')\n",
    "    df = pd.DataFrame(appian_feats[0]['outputs'], columns=[f'appian_cnn_{i}' for i in range(2048)])\n",
    "    df['ID'] = appian_feats[0]['ids']\n",
    "    test_list[n_fold] = test_list[n_fold].merge(df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('test_8models_stackfeats_add_appian_feats.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_list, f, protocol=4)\n",
    "# with open('train_8model_stackfeats_add_appian_feats.pickle', 'wb') as f:\n",
    "#     pickle.dump(train, f, protocol=4)\n",
    "# import pickle\n",
    "# with open('test_8models_stackfeats_add_appian_feats.pickle', 'rb') as f:\n",
    "#     test_list = pickle.load(f)\n",
    "# with open('train_8model_stackfeats_add_appian_feats.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "with open('test_10models_stackfeats_add_appian_feats.pickle', 'wb') as f:\n",
    "    pickle.dump(test_list, f, protocol=4)\n",
    "with open('train_10model_stackfeats_add_appian_feats.pickle', 'wb') as f:\n",
    "    pickle.dump(train, f, protocol=4)\n",
    "# import pickle\n",
    "# with open('test_10models_stackfeats_add_appian_feats.pickle', 'rb') as f:\n",
    "#     test_list = pickle.load(f)\n",
    "# with open('train_10model_stackfeats_add_appian_feats.pickle', 'rb') as f:\n",
    "#     train = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_cols = train.columns.drop(['ID', 'folds', 'StudyInstanceUID'] + target_cols)\n",
    "X_cols = test_list[0].columns.drop(['ID'])\n",
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.101205\n",
      "[200]\tvalid_0's binary_logloss: 0.101415\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.101152\n",
      "0.10115229136373897\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.015441\n",
      "[200]\tvalid_0's binary_logloss: 0.0159326\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.0153426\n",
      "0.015342644771518933\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0860191\n",
      "[200]\tvalid_0's binary_logloss: 0.0870095\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.0858931\n",
      "0.08589308272054638\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0659112\n",
      "[200]\tvalid_0's binary_logloss: 0.0654002\n",
      "[300]\tvalid_0's binary_logloss: 0.0654729\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.0653374\n",
      "0.06533735650190609\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0267038\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.0265111\n",
      "0.026511131687616114\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0376851\n",
      "[200]\tvalid_0's binary_logloss: 0.0375998\n",
      "[300]\tvalid_0's binary_logloss: 0.0374732\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.0374533\n",
      "0.037453287004873985\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0937956\n",
      "[200]\tvalid_0's binary_logloss: 0.093084\n",
      "[300]\tvalid_0's binary_logloss: 0.0929905\n",
      "[400]\tvalid_0's binary_logloss: 0.0927786\n",
      "[500]\tvalid_0's binary_logloss: 0.0929621\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's binary_logloss: 0.0927439\n",
      "0.09274391962152687\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0169493\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.0164399\n",
      "0.016439860092719163\n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 120 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.078439\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.0781802\n",
      "0.07818016441443577\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "stack_preds = []\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 5,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"verbosity\": 0,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "res = []\n",
    "pred_test = []\n",
    "fi = {}\n",
    "for c in target_cols:\n",
    "    fi[c] = []\n",
    "stack_preds_valid = []\n",
    "for i in range(5):\n",
    "    tr = train.query('folds != @i')\n",
    "    va = train.query('folds == @i')\n",
    "    preds = pd.DataFrame(np.zeros([len(va), 6]), columns = [c + '_pred' for c in target_cols])\n",
    "    for tar_col in target_cols:\n",
    "        tr_D = lgb.Dataset(tr[X_cols], tr[tar_col])\n",
    "        va_D = lgb.Dataset(va[X_cols], va[tar_col])\n",
    "        clf = lgb.train(params, tr_D, 10000, valid_sets=va_D, verbose_eval=100,\n",
    "                                    early_stopping_rounds=120)\n",
    "        preds[tar_col + '_pred'] = clf.predict(va[X_cols])\n",
    "        pred_test.append(clf.predict(test_list[i][X_cols]))\n",
    "        df_fi = pd.DataFrame(clf.feature_importance(importance_type='gain'), index = X_cols, columns=['FI_score'])\n",
    "        fi[tar_col].append(df_fi)\n",
    "        print(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        res.append(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        print('-'*80)\n",
    "    print('='*80)\n",
    "    stack_preds.append([va['ID'], preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(res):\n",
    "    score = 0\n",
    "    for i, r in enumerate(res):\n",
    "        if i %6 == 0:\n",
    "            score += 2*r\n",
    "        else:\n",
    "            score += r\n",
    "    return score/5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "preds_test_df = pd.DataFrame()\n",
    "for n_fold in range(5):\n",
    "    for n_target in range(6):\n",
    "        preds_test_df[target_cols[n_target] + '_' + str(n_fold) + 'fold'] = pred_test[n_fold*6 + n_target]\n",
    "preds_test_df.index = test['ID'].values\n",
    "preds_test_df = preds_test_df.loc[sub[0]['ids']]\n",
    "pred_test_sorted_list = []\n",
    "for i in range(30):\n",
    "    pred_test_sorted_list.append(preds_test_df.iloc[:, i].values)\n",
    "pred_test_df_list = []\n",
    "for n_fold in range(5):\n",
    "    tmp = np.zeros([len(test), 6])\n",
    "    for n_tar in range(6):\n",
    "        tmp[:, n_tar] = pred_test_sorted_list[6*n_fold + n_tar]\n",
    "    pred_test_df = pd.DataFrame(tmp, columns = target_cols)\n",
    "    pred_test_df_list.append(pred_test_df)\n",
    "sub = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "sub_original = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "for i in range(5):\n",
    "    sub[i]['outputs'] = pred_test_df_list[i][target_cols].values\n",
    "for i in range(5):\n",
    "    for ii in range(6):\n",
    "        print(np.corrcoef(sub[i]['outputs'][:, ii], sub_original[i]['outputs'][:, ii])[0, 1])\n",
    "path_to = '../stack_prediction/pred_test_1103_add_appian_feats.pkl'\n",
    "with open(path_to, 'wb') as f:\n",
    "    pickle.dump(sub, f)\n",
    "path_to = f'../stack_prediction/pred_valid_1103_add_appian_feats.pkl'\n",
    "with open(path_to, 'wb') as f:\n",
    "    pickle.dump(stack_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the correlation of submits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(appian_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99604635],\n",
       "       [0.99604635, 1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv('../model/model001/stack_1031_nobag.csv')\n",
    "a2 = pd.read_csv('../model/seresnext410/stack_1031_resnext410.csv')\n",
    "np.corrcoef(a1['Label'], a2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99912219],\n",
       "       [0.99912219, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv('../model/seresnext410/stack_1031_resnext410_dart.csv')\n",
    "a2 = pd.read_csv('../model/seresnext410/stack_1031_resnext410.csv')\n",
    "np.corrcoef(a1['Label'], a2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99264155],\n",
       "       [0.99264155, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv('../model/model001/stack_1031_nobag.csv')\n",
    "a2 = pd.read_csv('../model/inceptionv4/stack_1031_inceptionv4.csv')\n",
    "np.corrcoef(a1['Label'], a2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('../model/inceptionv4/stack_1031_inceptionv4.csv')\n",
    "p2 = pd.read_csv('../model/seresnext410/stack_1031_resnext410.csv')\n",
    "p3 = pd.read_csv('../model/seresnext410/stack_1031_resnext410_dart.csv')\n",
    "p4 = pd.read_csv('../model/model001/stack_1031_2.csv')\n",
    "p5 = pd.read_csv('../model/model001/stack_1031_model001_dart.csv')\n",
    "p6 = pd.read_csv('../model/inceptionv4/stack_1031_inceptionv4_dart.csv')\n",
    "p = p1['Label'] * 0.15 + p5['Label'] * 0.15 + p2['Label'] * 0.15 + p3['Label'] * 0.15 + p4['Label'] * 0.2 + p6['Label'] * 0.2\n",
    "a1['Label'] = p.values * 0.98\n",
    "a1.to_csv('1031_stack_seresnext512_30_seresnext410_25_seresnext410dart_25_seresnext410_20_2_multi098.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010550126945637375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99931158],\n",
       "       [0.99931158, 1.        ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv('../model/model001/stack_1031_nobag.csv')\n",
    "a2 = pd.read_csv('../model/model001/stack_1031_2.csv')\n",
    "np.corrcoef(a1['Label'], a2['Label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
