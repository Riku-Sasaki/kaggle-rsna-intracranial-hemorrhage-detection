{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "def wlogloss(targets, preds):\n",
    "    target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n",
    "    res = 0\n",
    "    for col in target_cols:\n",
    "        res += log_loss(targets[col], preds[col+'_pred'])\n",
    "        if col == 'any':\n",
    "            res += log_loss(targets[col], preds[col+'_pred'])\n",
    "    res /= 7\n",
    "    return res\n",
    "\n",
    "target_cols = ['any', 'epidural', 'subdural', 'subarachnoid', 'intraventricular', 'intraparenchymal']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_6models_fasterfeats.pickle', 'rb') as f:\n",
    "    test_list = pickle.load(f)\n",
    "with open('train_6model_fasterfeats.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = test_list[0].columns.drop(['ID'])\n",
    "X_cols = [c for c in X_cols if not c.endswith('div')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "_mean = train[X_cols].mean()\n",
    "scaler.fit(train[X_cols].fillna(_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2048, input_dim=len(X_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "stack_preds = []\n",
    "res = []\n",
    "pred_test = []\n",
    "fi = {}\n",
    "for c in target_cols:\n",
    "    fi[c] = []\n",
    "stack_preds_valid = []\n",
    "\n",
    "for i in range(5):\n",
    "    tr = train.query('folds != @i')\n",
    "    tr[X_cols] = tr[X_cols].fillna(_mean)\n",
    "    va = train.query('folds == @i')\n",
    "    va[X_cols] = va[X_cols].fillna(_mean)\n",
    "    print('fitting')\n",
    "    preds = pd.DataFrame(np.zeros([len(va), 6]), columns = [c + '_pred' for c in target_cols])\n",
    "    for tar_col in target_cols:\n",
    "        es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "        chkpt = f'stack2_{i}fold_{tar_col}.hdf5'\n",
    "        cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        model.fit(scaler.transform(tr[X_cols].values), tr[tar_col].values, nb_epoch=100, batch_size=512, validation_data=(scaler.transform(va[X_cols].values), va[tar_col].values), verbose=2, callbacks=[es_cb,cp_cb])\n",
    "        model.load_weights(chkpt)\n",
    "        preds[tar_col + '_pred'] = model.predict(scaler.transform(va[X_cols].values))\n",
    "        pred_test.append(model.predict(scaler.transform(test_list[i][X_cols].values)))\n",
    "        print(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        res.append(log_loss(va[tar_col], preds[tar_col + '_pred']))\n",
    "        print('-'*80)\n",
    "    print('='*80)\n",
    "    stack_preds.append([va['ID'], preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(res):\n",
    "    score = 0\n",
    "    for i, r in enumerate(res):\n",
    "        if i %6 == 0:\n",
    "            score += 2*r\n",
    "        else:\n",
    "            score += r\n",
    "    return score/5/7\n",
    "get_score(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../prediction/appian/'\n",
    "n_fold = 0\n",
    "sub = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "test = test_list[0]\n",
    "preds_test_df = pd.DataFrame()\n",
    "for n_fold in range(5):\n",
    "    for n_target in range(6):\n",
    "        preds_test_df[target_cols[n_target] + '_' + str(n_fold) + 'fold'] = pred_test[n_fold*6 + n_target].reshape(-1)\n",
    "preds_test_df.index = test['ID'].values\n",
    "preds_test_df = preds_test_df.loc[sub[0]['ids']]\n",
    "pred_test_sorted_list = []\n",
    "for i in range(30):\n",
    "    pred_test_sorted_list.append(preds_test_df.iloc[:, i].values)\n",
    "pred_test_df_list = []\n",
    "for n_fold in range(5):\n",
    "    tmp = np.zeros([len(test), 6])\n",
    "    for n_tar in range(6):\n",
    "        tmp[:, n_tar] = pred_test_sorted_list[6*n_fold + n_tar]\n",
    "    pred_test_df = pd.DataFrame(tmp, columns = target_cols)\n",
    "    pred_test_df_list.append(pred_test_df)\n",
    "sub = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "sub_original = pd.read_pickle(f'{path}/fold{n_fold}_ep2_test_tta5.pkl')\n",
    "for i in range(5):\n",
    "    sub[i]['outputs'] = pred_test_df_list[i][target_cols].values\n",
    "for i in range(5):\n",
    "    for ii in range(6):\n",
    "        print(np.corrcoef(sub[i]['outputs'][:, ii], sub_original[i]['outputs'][:, ii])[0, 1])\n",
    "path_to = '../stack_prediction/pred_test_1103_NN_7model_large_feats.pkl'\n",
    "with open(path_to, 'wb') as f:\n",
    "    pickle.dump(sub, f)\n",
    "path_to = f'../stack_prediction/pred_valid_1103_NN_7model_large_feats.pkl'\n",
    "with open(path_to, 'wb') as f:\n",
    "    pickle.dump(stack_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
